# ğŸ“¦ Gerekli kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
print(f"KullanÄ±lan SHAP KÃ¼tÃ¼phane SÃ¼rÃ¼mÃ¼: {shap.__version__}")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    confusion_matrix, accuracy_score, f1_score, classification_report,
    precision_recall_curve, roc_auc_score, roc_curve
)
from sklearn.inspection import PartialDependenceDisplay

# ğŸ”¹ Google Colab'da dosya yÃ¼kleme
from google.colab import files
print("LÃ¼tfen 'simule_uretim_verisi.csv' adlÄ± veri dosyanÄ±zÄ± seÃ§in:")
uploaded = files.upload()

# ğŸ”¹ Veriyi oku
df = None
df_original_for_ts_plots = None # Zaman serisi Ã§izimleri iÃ§in orijinal df'i sakla
try:
    file_name_to_load = "simule_uretim_verisi.csv" # YÃ¼klenecek dosya adÄ± bu olmalÄ±
    actual_file_name_uploaded = None

    if len(uploaded.keys()) == 0:
        raise FileNotFoundError("HiÃ§bir dosya yÃ¼klenmedi.")
    
    # YÃ¼klenen dosya adÄ±nÄ± bul (Colab bazen dosya adÄ±nÄ± deÄŸiÅŸtirebilir)
    # En olasÄ± eÅŸleÅŸmeyi bulmaya Ã§alÄ±ÅŸalÄ±m
    if file_name_to_load in uploaded:
        actual_file_name_uploaded = file_name_to_load
    else: # EÄŸer tam eÅŸleÅŸme yoksa, yÃ¼klenen ilk dosyayÄ± al
        actual_file_name_uploaded = list(uploaded.keys())[0]
        print(f"UYARI: Beklenen dosya adÄ± '{file_name_to_load}' bulunamadÄ±. YÃ¼klenen dosya: '{actual_file_name_uploaded}' kullanÄ±lacak.")
            
    df = pd.read_csv(io.BytesIO(uploaded[actual_file_name_uploaded])) # io.BytesIO eklendi
    print(f"'{actual_file_name_uploaded}' baÅŸarÄ±yla yÃ¼klendi.")
    print(f"Veri seti boyutu: {df.shape}")
    print("\nVeri Setinin Ä°lk 5 SatÄ±rÄ±:")
    print(df.head())
    print("\nVeri Seti Bilgileri:")
    df.info()
    df_original_for_ts_plots = df.copy() # Orijinal df'i kopyala

except FileNotFoundError as fnf_e:
    print(f"HATA: Dosya yÃ¼klenmedi veya bulunamadÄ±. {fnf_e}")
    exit()
except Exception as e:
    print(f"Dosya okunurken bir hata oluÅŸtu: {e}")
    exit()

# ğŸ“Œ Korelasyon Matrisi (HAM VERÄ° ÃœZERÄ°NDEN - Tarih ve kategorikler Ã§Ä±karÄ±lmadan Ã¶nce)
try:
    print("\n--- Ham Veri Korelasyon Matrisi ---")
    plt.figure(figsize=(12, 10))
    # Sadece sayÄ±sal sÃ¼tunlarÄ± al, object/string tipindekileri ve tarihi dÄ±ÅŸarÄ±da bÄ±rakmaya Ã§alÄ±ÅŸ
    numeric_cols_for_raw_corr = df.select_dtypes(include=np.number).columns.tolist()
    if 'tarih' in df.columns and df['tarih'].dtype == 'object': # EÄŸer tarih object ise korelasyondan Ã§Ä±kar
        pass # Zaten select_dtypes(include=np.number) bunu yapacaktÄ±r
    
    if numeric_cols_for_raw_corr:
        sns.heatmap(df[numeric_cols_for_raw_corr].corr(), annot=True, cmap='coolwarm', fmt=".2f")
        plt.title("Korelasyon Matrisi (Sadece SayÄ±sal Ã–zellikler - Ham Veri)")
        plt.tight_layout()
        plt.show()
    else:
        print("Ham veri korelasyon matrisi iÃ§in sayÄ±sal sÃ¼tun bulunamadÄ±.")
except Exception as e:
    print(f"Ä°lk korelasyon matrisi Ã§izilirken hata: {e}")


# --- Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ°: TARÄ°H VE OLAY BÄ°LGÄ°LERÄ° ---
df_processed = df.copy() 
newly_created_time_features = []
# Kategorik ve sayÄ±sal Ã¶zellikleri ham df_processed Ã¼zerinden belirleyelim
temp_X_for_feature_detection = df_processed.drop('hata_var', axis=1, errors='ignore')

# 'vardiya' ve 'makine_id' kategorik olarak kabul edilecekse
original_categorical_features = []
if 'vardiya' in temp_X_for_feature_detection.columns: original_categorical_features.append('vardiya')
if 'makine_id' in temp_X_for_feature_detection.columns: original_categorical_features.append('makine_id') # makine_id'yi de kategorik alalÄ±m

original_numerical_features = [
    col for col in temp_X_for_feature_detection.columns 
    if col not in original_categorical_features and col != 'tarih' and \
    df_processed[col].dtype in [np.int64, np.int32, np.float64, int, float]
]

try:
    print("\nğŸ”§ Ã–zellik MÃ¼hendisliÄŸi BaÅŸlÄ±yor...")
    if 'tarih' in df_processed.columns:
        df_processed['tarih'] = pd.to_datetime(df_processed['tarih'])
        df_processed['yil'] = df_processed['tarih'].dt.year
        df_processed['ay'] = df_processed['tarih'].dt.month
        df_processed['gun'] = df_processed['tarih'].dt.day
        df_processed['haftanin_gunu'] = df_processed['tarih'].dt.dayofweek # Pazartesi=0, Pazar=6
        df_processed['yilin_gunu'] = df_processed['tarih'].dt.dayofyear
        df_processed['hafta_numarasi'] = df_processed['tarih'].dt.isocalendar().week.astype(int)
        newly_created_time_features = ['yil', 'ay', 'gun', 'haftanin_gunu', 'yilin_gunu', 'hafta_numarasi']
        print(f"'tarih' sÃ¼tunundan yeni zaman Ã¶zellikleri tÃ¼retildi: {newly_created_time_features}")
        
        # === YENÄ°: Zaman Serisi Grafikleri iÃ§in Tarih Index'li df_original_for_ts_plots'u kullanalÄ±m ===
        if df_original_for_ts_plots is not None and 'tarih' in df_original_for_ts_plots.columns:
            try:
                df_original_for_ts_plots['tarih'] = pd.to_datetime(df_original_for_ts_plots['tarih'])
                df_original_for_ts_plots.set_index('tarih', inplace=True)
                print("Orijinal veri seti zaman serisi analizleri iÃ§in indexlendi.")
            except Exception as e_ts_index:
                print(f"Zaman serisi iÃ§in orijinal df indexlenirken hata: {e_ts_index}")
        
        if 'rulman_degisimi_sonrasi' in df_processed.columns:
            print("'rulman_degisimi_sonrasi' Ã¶zelliÄŸi zaten mevcut.")
            if df_processed['rulman_degisimi_sonrasi'].dtype == 'object':
                try: df_processed['rulman_degisimi_sonrasi'] = pd.to_numeric(df_processed['rulman_degisimi_sonrasi'], errors='coerce').fillna(0) # SayÄ±ya Ã§evir, Ã§eviremezse 0 yap
                except ValueError: print(f"UYARI: 'rulman_degisimi_sonrasi' sayÄ±ya Ã§evrilemedi.")
        
        # 'tarih' sÃ¼tunu, zaman Ã¶zellikleri tÃ¼retildikten sonra modelleme iÃ§in Ã§Ä±karÄ±lÄ±r
        df_processed = df_processed.drop('tarih', axis=1)
        print("'tarih' sÃ¼tunu modelleme iÃ§in Ã¶zelliklerden Ã§Ä±karÄ±ldÄ± (zaman Ã¶zellikleri tÃ¼retildi).")
    else:
        print("UYARI: 'tarih' sÃ¼tunu bulunamadÄ±. Zaman Ã¶zellikleri tÃ¼retilemedi.")
except Exception as e:
    print(f"Ã–zellik mÃ¼hendisliÄŸi sÄ±rasÄ±nda hata oluÅŸtu: {e}")
    df_processed = df.copy() 
    if 'tarih' in df_processed.columns:
        df_processed = df_processed.drop('tarih', axis=1, errors='ignore')

# === YENÄ°: ZAMAN SERÄ°SÄ° GÃ–RSELLEÅTÄ°RMELERÄ° (Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ°NDEN SONRA, df_original_for_ts_plots ÃœZERÄ°NDEN) ===
if df_original_for_ts_plots is not None and isinstance(df_original_for_ts_plots.index, pd.DatetimeIndex):
    print("\n--- Zaman Serisi GÃ¶rselleÅŸtirmeleri (HAM VERÄ° ÃœZERÄ°NDEN) ---")

    # Tek bir makinenin titreÅŸim verisi (Ã–rnek: ilk makine_id)
    if 'makine_id' in df_original_for_ts_plots.columns and 'titreÅŸim' in df_original_for_ts_plots.columns:
        makine_id_to_plot = df_original_for_ts_plots['makine_id'].unique()[0]
        makine_data = df_original_for_ts_plots[df_original_for_ts_plots['makine_id'] == makine_id_to_plot]['titreÅŸim']
        if not makine_data.empty:
            plt.figure(figsize=(15, 5))
            makine_data.plot(title=f'Makine {makine_id_to_plot} - TitreÅŸim Zaman Serisi', legend=True)
            plt.ylabel('TitreÅŸim')
            plt.show()

    # TÃ¼m makinelerin ortalama sÄ±caklÄ±k trendi (GÃ¼nlÃ¼k ortalama)
    if 'sicaklik' in df_original_for_ts_plots.columns:
        plt.figure(figsize=(15, 5))
        df_original_for_ts_plots['sicaklik'].resample('D').mean().plot(title='GÃ¼nlÃ¼k Ortalama SÄ±caklÄ±k Zaman Serisi', legend=True)
        plt.ylabel('Ortalama SÄ±caklÄ±k [K]')
        plt.show()

    # Rulman_degisimi_sonrasi etkisini incele (TÃ¼m makine ID'leri iÃ§in genel veya Ã¶rnek bir makine)
    if 'rulman_degisimi_sonrasi' in df_original_for_ts_plots.columns and 'titreÅŸim' in df_original_for_ts_plots.columns:
        plt.figure(figsize=(12, 6))
        sns.boxplot(x='rulman_degisimi_sonrasi', y='titreÅŸim', data=df_original_for_ts_plots)
        plt.title('Rulman Durumuna GÃ¶re TitreÅŸim DaÄŸÄ±lÄ±mÄ± (TÃ¼m Makineler)')
        plt.show()

        # Ã–rnek bir makine iÃ§in zaman serisinde rulman durumunun etkisi
        makine_id_for_rulman_plot = df_original_for_ts_plots['makine_id'].unique()[0] # Ä°lk makine
        df_makine_rulman = df_original_for_ts_plots[df_original_for_ts_plots['makine_id'] == makine_id_for_rulman_plot]
        if not df_makine_rulman.empty:
            plt.figure(figsize=(15, 7))
            sns.lineplot(data=df_makine_rulman, x=df_makine_rulman.index, y='titreÅŸim', hue='rulman_degisimi_sonrasi', palette='viridis', legend='full')
            plt.title(f'Makine {makine_id_for_rulman_plot} - TitreÅŸim ve Rulman DeÄŸiÅŸimi SonrasÄ± Durum')
            plt.ylabel('TitreÅŸim')
            plt.show()
else:
    print("\nZaman serisi grafikleri iÃ§in 'tarih' index olarak ayarlanmalÄ± veya df_original_for_ts_plots uygun deÄŸil.")

# === YENÄ°: HATA DURUMLARI VE RULMAN Ä°LÄ°ÅKÄ°SÄ° (df_processed Ã¼zerinden, Ã¶zellikler tÃ¼retildikten sonra) ===
if 'hata_var' in df_processed.columns and 'rulman_degisimi_sonrasi' in df_processed.columns:
    print("\n--- Hata DurumlarÄ± ve Rulman Ä°liÅŸkisi ---")
    hata_rulman_crosstab = pd.crosstab(df_processed['rulman_degisimi_sonrasi'], df_processed['hata_var'])
    print("\nRulman Durumuna GÃ¶re Hata SayÄ±larÄ±:\n", hata_rulman_crosstab)
    if not hata_rulman_crosstab.empty:
        hata_rulman_crosstab.plot(kind='bar', stacked=False, figsize=(12,7), colormap='viridis')
        plt.title('Rulman Durumuna GÃ¶re Hata DaÄŸÄ±lÄ±mÄ±')
        plt.ylabel('SayÄ±')
        plt.xlabel('Rulman DeÄŸiÅŸimi SonrasÄ± Durum (0-4)')
        plt.xticks(rotation=0)
        plt.legend(title='Hata Var', labels=['Hata Yok', 'Hata Var'])
        plt.show()

# === PROPHET Ä°LE ZAMAN SERÄ°SÄ° TAHMÄ°NÄ° (YENÄ° BÃ–LÃœM) ===
print("\n--- Prophet ile Zaman Serisi Tahmini ---")
try:
    from prophet import Prophet
    print("Prophet kÃ¼tÃ¼phanesi baÅŸarÄ±yla yÃ¼klendi.")

    if df_original_for_ts_plots is not None and isinstance(df_original_for_ts_plots.index, pd.DatetimeIndex):
        # Ã–rnek olarak ilk makinenin titreÅŸim verisini alalÄ±m
        makine_id_for_prophet = df_original_for_ts_plots['makine_id'].unique()[0]
        df_prophet_input = df_original_for_ts_plots[df_original_for_ts_plots['makine_id'] == makine_id_for_prophet][['titreÅŸim']].reset_index()
        df_prophet_input.rename(columns={'tarih': 'ds', 'titreÅŸim': 'y'}, inplace=True)

        if not df_prophet_input.empty and len(df_prophet_input) > 2 : # Prophet en az 2 veri noktasÄ± ister
            print(f"\nMakine {makine_id_for_prophet} iÃ§in Prophet modeli hazÄ±rlanÄ±yor (hedef: titreÅŸim)...")

            # OlaylarÄ± (rulman deÄŸiÅŸimi) tanÄ±mla
            # 'rulman_degisimi_sonrasi == 0' olan tarihleri bulalÄ±m
            # Bu kÄ±sÄ±m, rulman_degisimi_sonrasi sÃ¼tununun anlamÄ±na gÃ¶re uyarlanmalÄ±
            rulman_degisim_tarihleri = df_original_for_ts_plots[
                (df_original_for_ts_plots['makine_id'] == makine_id_for_prophet) & 
                (df_original_for_ts_plots['rulman_degisimi_sonrasi'] == 0) # Veya deÄŸiÅŸimi gÃ¶steren baÅŸka bir mantÄ±k
            ].index.tolist()

            holidays_df = None
            if rulman_degisim_tarihleri:
                holidays_df = pd.DataFrame({
                    'holiday': 'rulman_degisimi',
                    'ds': pd.to_datetime(rulman_degisim_tarihleri),
                    'lower_window': 0, # OlayÄ±n sadece o gÃ¼n etkili olduÄŸunu varsayalÄ±m
                    'upper_window': 1  # OlayÄ±n ertesi gÃ¼n de bir miktar etkisi olabilir (ayarlanabilir)
                })
                print(f"Rulman deÄŸiÅŸimi olaylarÄ± bulundu: {len(holidays_df)} adet")

            # Prophet modelini oluÅŸtur ve eÄŸit
            prophet_model = Prophet(holidays=holidays_df, daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True, seasonality_mode='additive')
            # Gerekirse 'changepoint_prior_scale' gibi parametreler ayarlanabilir.
            
            # EÄŸer harici regresÃ¶r (extra regressors) eklemek istersek:
            # Ã–rneÄŸin, Ã¼retim hÄ±zÄ±nÄ±n titreÅŸimi etkilediÄŸini dÃ¼ÅŸÃ¼nÃ¼yorsak:
            # df_prophet_input['uretim_hizi'] = df_original_for_ts_plots.loc[df_prophet_input['ds'], 'uretim_hizi'].values # ds'e gÃ¶re eÅŸleÅŸtir
            # prophet_model.add_regressor('uretim_hizi')

            prophet_model.fit(df_prophet_input)

            # Gelecek iÃ§in tahmin yap (Ã¶rneÄŸin 90 gÃ¼n sonrasÄ±)
            future_dates = prophet_model.make_future_dataframe(periods=90, freq='D')
            
            # EÄŸer regresÃ¶r eklediysek future_dates'e o regresÃ¶rÃ¼n gelecek deÄŸerlerini de eklememiz gerekir.
            # if 'uretim_hizi' in df_prophet_input.columns:
            #    # Bu kÄ±sÄ±m iÃ§in Ã¼retim hÄ±zÄ±nÄ±n gelecek deÄŸerlerini tahmin etmek veya varsaymak gerekir.
            #    # Basitlik adÄ±na son deÄŸeri sabit tutabiliriz veya bir trend uygulayabiliriz.
            #    last_uretim_hizi = df_prophet_input['uretim_hizi'].iloc[-1]
            #    future_dates['uretim_hizi'] = last_uretim_hizi # Ã‡ok basit bir varsayÄ±m

            forecast = prophet_model.predict(future_dates)

            print("\nTahmin SonuÃ§larÄ± (Ä°lk BirkaÃ§Ä± ve Son BirkaÃ§Ä±):")
            print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())
            print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())

            # Tahminleri ve bileÅŸenleri Ã§izdir
            fig1 = prophet_model.plot(forecast)
            plt.title(f'Makine {makine_id_for_prophet} - TitreÅŸim Tahmini')
            plt.show()

            fig2 = prophet_model.plot_components(forecast)
            plt.show()
            
        else:
            print(f"Makine {makine_id_for_prophet} iÃ§in Prophet modeli eÄŸità²²à³ yeterli veri yok.")
    else:
        print("Prophet analizi iÃ§in zaman indexli orijinal veri seti (df_original_for_ts_plots) bulunamadÄ±.")

except ImportError:
    print("Prophet kÃ¼tÃ¼phanesi bulunamadÄ±. YÃ¼klemek iÃ§in: !pip install prophet")
except Exception as e_prophet:
    print(f"Prophet analizi sÄ±rasÄ±nda bir hata oluÅŸtu: {e_prophet}")


# X ve y'yi Ã¶zellik mÃ¼hendisliÄŸi tamamlanmÄ±ÅŸ df_processed'dan ayÄ±ralÄ±m
if 'hata_var' not in df_processed.columns:
    print("HATA: Hedef deÄŸiÅŸken 'hata_var' df_processed iÃ§inde bulunamadÄ±!")
    exit()

X = df_processed.drop('hata_var', axis=1) 
y = df_processed['hata_var']

# Kategorik ve sayÄ±sal Ã¶zellikleri X Ã¼zerinden yeniden belirleyelim (tÃ¼retilmiÅŸ zaman Ã¶zellikleri dahil)
categorical_features = []
if 'vardiya' in X.columns: categorical_features.append('vardiya') # One-hot sonrasÄ± bu olmayacak
if 'makine_id' in X.columns: categorical_features.append('makine_id') # Kategorik alÄ±nacaksa

# One-Hot sonrasÄ± oluÅŸan 'vardiya_...' sÃ¼tunlarÄ±nÄ± yakala
one_hot_vardiya_cols = [col for col in X.columns if col.startswith('vardiya_')]
# 'yil', 'ay' gibi tÃ¼retilmiÅŸ zaman Ã¶zellikleri de sayÄ±sal ama farklÄ± ele alÄ±nabilir
# Åimdilik tÃ¼m sayÄ±sal gÃ¶rÃ¼nenleri alalÄ±m

# Nihai kategorik Ã¶zellikler (One-Hot Ã¶ncesi)
final_categorical_to_encode = []
if 'vardiya' in X.columns: final_categorical_to_encode.append('vardiya') # 'vardiya' OneHot ile iÅŸlenecekse
if 'makine_id' in df.columns and df['makine_id'].nunique() < 20 : # EÄŸer makine_id Ã§ok Ã§eÅŸitli deÄŸilse kategorik alÄ±nabilir.
    final_categorical_to_encode.append('makine_id')


final_numerical_features = [
    col for col in X.columns 
    if col not in final_categorical_to_encode and col not in newly_created_time_features and \
    X[col].dtype in [np.int64, np.int32, np.float64]
]
# Zaman Ã¶zelliklerini de sayÄ±sal olarak ekleyebiliriz
final_numerical_features.extend(newly_created_time_features)
final_numerical_features = list(set(final_numerical_features)) # Benzersiz yap

print(f"\nÃ–zellik mÃ¼hendisliÄŸi sonrasÄ± X'in sÃ¼tunlarÄ±: {X.columns.tolist()}")
print(f"Model iÃ§in kullanÄ±lacak SayÄ±sal Ã–zellikler: {final_numerical_features}")
print(f"Model iÃ§in kullanÄ±lacak Kategorik Ã–zellikler (One-Hot Ã¶ncesi): {final_categorical_to_encode}")


# Eksik veri doldurma (EÄŸer Ã¶zellik mÃ¼hendisliÄŸi sonrasÄ± oluÅŸtuysa)
for col in final_numerical_features:
    if col in X.columns and X[col].isnull().sum() > 0: X[col].fillna(X[col].mean(), inplace=True)
for col in final_categorical_to_encode: # One-hot Ã¶ncesi kategorik sÃ¼tunlar iÃ§in
    if col in X.columns and X[col].isnull().sum() > 0: X[col].fillna(X[col].mode()[0], inplace=True)
print("Eksik veriler (gerekliyse) dolduruldu.")


# Preprocessing pipeline
transformers_list = []
# SayÄ±sal Ã¶zellikler
if valid_numerical_features := [f for f in final_numerical_features if f in X.columns]:
    transformers_list.append(('num', StandardScaler(), valid_numerical_features))
# Kategorik Ã¶zellikler (One-Hot)
if valid_categorical_features := [f for f in final_categorical_to_encode if f in X.columns]:
    transformers_list.append(('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), valid_categorical_features))

if not transformers_list: print("HATA: Ã–n iÅŸleme iÃ§in Ã¶zellik bulunamadÄ±."); exit()
preprocessor = ColumnTransformer(transformers=transformers_list, remainder='passthrough') # remainder='passthrough' Ã¶nemli


# Veriyi EÄŸitim ve Test Setlerine AyÄ±rma
try: 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)
except ValueError as e: 
    print(f"Stratify hatasÄ±: {e}. Stratify olmadan devam ediliyor.")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
print(f"EÄŸitim seti: {X_train.shape}, Test seti: {X_test.shape}")


# Modeller (Mevcut kodunuzdaki gibi)
models_to_evaluate = {
    "Logistic Regression": LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced', max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),
    "Support Vector Machine": SVC(probability=True, class_weight='balanced', random_state=42)
}
xgboost_available = False; lightgbm_available = False
try:
    from xgboost import XGBClassifier
    count_class_0_train = sum(y_train == 0); count_class_1_train = sum(y_train == 1)
    scale_pos_weight_xgb_train = count_class_0_train / count_class_1_train if count_class_1_train > 0 else 1
    models_to_evaluate["XGBoost"] = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=scale_pos_weight_xgb_train)
    xgboost_available = True
except ImportError: print_once("XGBoost kÃ¼tÃ¼phanesi bulunamadÄ±, atlanÄ±yor.")
try:
    from lightgbm import LGBMClassifier
    models_to_evaluate["LightGBM"] = LGBMClassifier(random_state=42, class_weight='balanced', n_jobs=-1) # is_unbalance=True de denenebilir
    lightgbm_available = True
except ImportError: print_once("LightGBM kÃ¼tÃ¼phanesi bulunamadÄ±, atlanÄ±yor.")

# Model DeÄŸerlendirme DÃ¶ngÃ¼sÃ¼ (Mevcut kodunuzdaki gibi)
model_results = {}
fig_roc_main, ax_roc_main = plt.subplots(figsize=(10, 8)); ax_roc_main.plot([0, 1], [0, 1], 'k--')

for model_name, classifier_instance in models_to_evaluate.items():
    print(f"\n--- {model_name} Modeli ---")
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier_instance)])
    try:
        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_test)
        y_proba_positive_class = pipeline.predict_proba(X_test)[:, 1] if hasattr(classifier_instance, "predict_proba") else None
        
        accuracy = accuracy_score(y_test, y_pred)
        f1_hata_var = f1_score(y_test, y_pred, pos_label=1, zero_division=0) # Hata sÄ±nÄ±fÄ± (1) iÃ§in F1
        report_dict = classification_report(y_test, y_pred, target_names=['Hata Yok (0)', 'Hata Var (1)'], output_dict=True, zero_division=0)
        cm = confusion_matrix(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_proba_positive_class) if y_proba_positive_class is not None else np.nan
        
        model_results[model_name] = {
            "Pipeline": pipeline, "Accuracy": accuracy, "F1 Score (Hata Var)": f1_hata_var,
            "Precision (Hata Var)": report_dict["Hata Var (1)"]["precision"], 
            "Recall (Hata Var)": report_dict["Hata Var (1)"]["recall"],
            "F1 Macro": report_dict["macro avg"]["f1-score"], "ROC AUC": roc_auc, 
            "Confusion Matrix": cm,
            "Probabilities (Pozitif SÄ±nÄ±f)": y_proba_positive_class
        }
        
        print(f"Accuracy: {accuracy:.4f}, F1 (Hata Var): {f1_hata_var:.4f}, ROC AUC: {roc_auc:.4f}" if y_proba_positive_class is not None else f"Acc: {accuracy:.4f}, F1: {f1_hata_var:.4f}, ROC AUC: N/A")
        print(classification_report(y_test, y_pred, target_names=['Hata Yok (0)', 'Hata Var (1)'], zero_division=0))
        
        fig_cm_ind, ax_cm_ind = plt.subplots(figsize=(6,4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm_ind);
        ax_cm_ind.set_title(f"Confusion Matrix - {model_name}"); ax_cm_ind.set_xlabel("Tahmin Edilen"); ax_cm_ind.set_ylabel("GerÃ§ek"); plt.show()
        
        if y_proba_positive_class is not None:
            fpr, tpr, _ = roc_curve(y_test, y_proba_positive_class); 
            ax_roc_main.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')
            
    except Exception as e: print(f"{model_name} ile hata: {type(e).__name__}: {e}")

ax_roc_main.set_xlabel('False Positive Rate'); ax_roc_main.set_ylabel('True Positive Rate'); ax_roc_main.set_title('Modeller iÃ§in ROC EÄŸrileri'); ax_roc_main.legend(loc='lower right'); ax_roc_main.grid(True); plt.show()

# SonuÃ§larÄ± DataFrame'e Aktarma (Mevcut kodunuzdaki gibi)
results_list_for_df = [(name, res.get("Accuracy",np.nan), res.get("F1 Score (Hata Var)",np.nan), res.get("Precision (Hata Var)",np.nan),
                        res.get("Recall (Hata Var)",np.nan), res.get("F1 Macro",np.nan), res.get("ROC AUC",np.nan))
                       for name, res in model_results.items()]
results_df = pd.DataFrame(results_list_for_df, columns=["Model", "Accuracy", "F1 Hata Var", "Precision Hata Var", "Recall Hata Var", "F1 Macro", "ROC AUC"])
print("\n--- TÃ¼m Modellerin Ã–zet PerformansÄ± ---"); print(results_df.sort_values(by="F1 Hata Var", ascending=False))


# En Ä°yi Model ve EÅŸik Ayarlama (Mevcut kodunuzdaki gibi, bazÄ± kÃ¼Ã§Ã¼k dÃ¼zeltmelerle)
best_model_overall_name = None; best_model_overall_pipeline = None; top_n_features_for_detail = 3 # SHAP iÃ§in
feature_importance_shap_df = pd.DataFrame() 

if not results_df.empty:
    try:
        sorted_results_df = results_df.sort_values(by="F1 Hata Var", ascending=False) # Hata sÄ±nÄ±fÄ± F1'e gÃ¶re sÄ±rala
        if not sorted_results_df.empty and sorted_results_df.iloc[0]["F1 Hata Var"] > 0 : # En azÄ±ndan bir miktar F1 skoru varsa
             best_model_overall_name = sorted_results_df.iloc[0]["Model"]
        if best_model_overall_name and best_model_overall_name in model_results: 
            best_model_overall_pipeline = model_results[best_model_overall_name]["Pipeline"]
        if best_model_overall_name: print(f"\nGenel en iyi model (F1 Hata Var'a gÃ¶re): '{best_model_overall_name}'")
        else: print("En iyi model (F1 Hata var > 0 olan) belirlenemedi.")
    except (IndexError, KeyError) as e: print(f"En iyi model belirlenirken hata: {e}"); best_model_overall_pipeline = None
else: print("Model sonuÃ§larÄ± (results_df) boÅŸ, en iyi model belirlenemiyor.")


if best_model_overall_pipeline:
    y_proba_best_overall = model_results[best_model_overall_name].get("Probabilities (Pozitif SÄ±nÄ±f)")
    best_threshold_glob = 0.5 
    if y_proba_best_overall is not None:
        print(f"\n--- '{best_model_overall_name}' modeli iÃ§in EÅŸik Ayarlama ---")
        precision_th, recall_th, thresholds_pr_th = precision_recall_curve(y_test, y_proba_best_overall)
        if len(precision_th)>1 and len(recall_th)>1 and len(thresholds_pr_th)>0:
            # Precision ve Recall'Ä±n son deÄŸeri (recall=0, precision=1) ve eÅŸik dizisinin fazladan elemanÄ±nÄ± Ã§Ä±kar
            fscore_pr_th=(2*precision_th[:-1]*recall_th[:-1])/(precision_th[:-1]+recall_th[:-1]+1e-9) # 1e-9 sÄ±fÄ±ra bÃ¶lme hatasÄ±nÄ± Ã¶nler
            if len(fscore_pr_th)>0:
                ix_pr = np.argmax(fscore_pr_th)
                # thresholds_pr_th, precision_th ve recall_th'den bir eksik elemana sahip olabilir
                best_threshold_glob=thresholds_pr_th[min(ix_pr, len(thresholds_pr_th)-1)] 
                print(f'En Ä°yi EÅŸik (max F1): {best_threshold_glob:.4f}'); 
                y_pred_best_thresh=(y_proba_best_overall>=best_threshold_glob).astype(int)
                print("\nEÅŸik AyarlanmÄ±ÅŸ Performans:"); 
                print(f"Acc: {accuracy_score(y_test,y_pred_best_thresh):.4f}, F1 (Hata Var): {f1_score(y_test,y_pred_best_thresh,pos_label=1,zero_division=0):.4f}")
                print(classification_report(y_test,y_pred_best_thresh,target_names=['Hata Yok (0)','Hata Var (1)'],zero_division=0))
                cm_bt = confusion_matrix(y_test,y_pred_best_thresh); 
                plt.figure(figsize=(6,5));sns.heatmap(cm_bt,annot=True,fmt='d',cmap='Greens');plt.title(f"CM - {best_model_overall_name} (EÅŸik {best_threshold_glob:.2f})");plt.show()
            else: print("F1 skorlarÄ± eÅŸik ayarlama iÃ§in hesaplanamadÄ±.")
        else: print("Precision/Recall eÄŸrisi iÃ§in yeterli veri yok.")
    else: 
        if best_model_overall_name: print(f"'{best_model_overall_name}' iÃ§in olasÄ±lÄ±k Ã§Ä±ktÄ±sÄ± yok, eÅŸik ayarlama atlandÄ±.")
else: print("EÅŸik ayarlanacak model bulunamadÄ±.")


# SHAP ve PDP Analizleri (Mevcut kodunuzdaki gibi, kÃ¼Ã§Ã¼k iyileÅŸtirmelerle)
print("\n--- DETAYLI Ã–ZELLÄ°K ANALÄ°ZÄ° (SHAP VE PDP) ---")
# ... (Mevcut SHAP ve PDP kodunuz buraya gelecek, preprocessor ve classifier'Ä± pipeline'dan alacak ÅŸekilde) ...
# SHAP iÃ§in X_train_transformed_df_shap ve X_test_transformed_df_shap oluÅŸtururken preprocessor'Ä±n doÄŸru kullanÄ±ldÄ±ÄŸÄ±ndan emin olun.
# En iyi modelin (best_model_overall_pipeline) preprocessor ve classifier adÄ±mlarÄ±nÄ± kullanarak bu analizleri yapÄ±n.
# SHAP ve PDP kodunuz zaten oldukÃ§a detaylÄ±, oradaki mantÄ±ÄŸÄ± koruyarak, 
# `shap_pipeline_to_analyze` deÄŸiÅŸkeninin doÄŸru ÅŸekilde atandÄ±ÄŸÄ±ndan emin olun.

# SHAP ve PDP kodunuzun bÃ¼yÃ¼k bir kÄ±smÄ±nÄ± olduÄŸu gibi kullanabilirsiniz,
# Sadece `shap_pipeline_to_analyze`'nin doÄŸru pipeline'Ä± iÅŸaret ettiÄŸinden
# ve `X_train`, `X_test`'in ham (Ã¶lÃ§eklenmemiÅŸ, encode edilmemiÅŸ) versiyonlar olduÄŸundan emin olun,
# Ã§Ã¼nkÃ¼ `preprocessor` bu dÃ¶nÃ¼ÅŸÃ¼mleri pipeline iÃ§inde yapacak.

# Ã–rnek SHAP/PDP entegrasyonu (kendi kodunuzu buraya uyarlayÄ±n):
if shap_pipeline_to_analyze: # Bu deÄŸiÅŸken yukarÄ±daki model seÃ§im mantÄ±ÄŸÄ±ndan gelmeli
    print(f"\n'{shap_model_to_analyze_name}' Ãœzerinden DetaylÄ± Analizler BaÅŸlÄ±yor.")
    try:
        current_preprocessor_shap = shap_pipeline_to_analyze.named_steps['preprocessor']
        classifier_for_shap = shap_pipeline_to_analyze.named_steps['classifier']
        
        # Transformed veriyi al
        X_train_transformed_for_shap = current_preprocessor_shap.transform(X_train)
        X_test_transformed_for_shap = current_preprocessor_shap.transform(X_test)
        
        # get_feature_names_out() ColumnTransformer'dan Ã¶zellik adlarÄ±nÄ± almak iÃ§in
        try:
            all_feature_names_shap = current_preprocessor_shap.get_feature_names_out()
        except AttributeError: # Eski sklearn versiyonlarÄ± iÃ§in fallback
            # Bu kÄ±sÄ±m karmaÅŸÄ±k olabilir, en iyisi sklearn'i gÃ¼ncellemek veya manuel adlandÄ±rma
            print("UYARI: get_feature_names_out kullanÄ±lamÄ±yor. SHAP Ã¶zellik adlarÄ± eksik olabilir.")
            all_feature_names_shap = [f"feature_{i}" for i in range(X_train_transformed_for_shap.shape[1])]


        X_train_transformed_df_shap = pd.DataFrame(X_train_transformed_for_shap, columns=all_feature_names_shap)
        X_test_transformed_df_shap = pd.DataFrame(X_test_transformed_for_shap, columns=all_feature_names_shap)

        # ... (Mevcut SHAP explainer ve plot kodlarÄ±nÄ±z buraya) ...
        # Ã–rnek:
        is_tree_explainer_model = isinstance(classifier_for_shap, (RandomForestClassifier, XGBClassifier if xgboost_available else type(None), LGBMClassifier if lightgbm_available else type(None) ))
        if is_tree_explainer_model:
            explainer = shap.TreeExplainer(classifier_for_shap, X_train_transformed_df_shap, feature_perturbation="interventional")
            shap_values_test = explainer.shap_values(X_test_transformed_df_shap) # Veya sadece explainer(X_test_transformed_df_shap)
            
            # shap_values genellikle (sÄ±nÄ±f_sayÄ±sÄ±, Ã¶rnek_sayÄ±sÄ±, Ã¶zellik_sayÄ±sÄ±) ÅŸeklinde gelir
            # Ä°kili sÄ±nÄ±flandÄ±rmada pozitif sÄ±nÄ±f iÃ§in olanÄ± alalÄ±m:
            shap_values_for_positive_class = shap_values_test[1] if isinstance(shap_values_test, list) and len(shap_values_test) == 2 else shap_values_test

            print("\nSHAP Summary Plot (Beeswarm):")
            shap.summary_plot(shap_values_for_positive_class, X_test_transformed_df_shap, feature_names=all_feature_names_shap, max_display=15)
            
            print("\nSHAP Summary Plot (Bar):")
            shap.summary_plot(shap_values_for_positive_class, X_test_transformed_df_shap, feature_names=all_feature_names_shap, plot_type="bar", max_display=15)

        else:
            print(f"'{shap_model_to_analyze_name}' iÃ§in uygun SHAP Explainer (Tree) bulunamadÄ±. KernelExplainer veya LinearExplainer deneyebilirsiniz.")

        # PDP
        # ... (Mevcut PDP kodunuz buraya, X_train orijinalini ve shap_pipeline_to_analyze'i kullanarak) ...
        # original_numerical_features_for_binning yerine SHAP'tan gelen en Ã¶nemli sayÄ±sal Ã¶zellikleri kullanÄ±n
        if 'feature_importance_shap_df' in locals() and not feature_importance_shap_df.empty:
            # SHAP'tan gelen Ã¶zellik adlarÄ± (Ã¶rn: num__sicaklik, cat__makine_id_2). Orijinal adlara map etmeniz gerekebilir.
            # Basitlik iÃ§in, SHAP dataframe'indeki ilk N sayÄ±sal Ã¶zelliÄŸi alÄ±p, __ Ã¶ncesini atarak orijinal adÄ± bulmaya Ã§alÄ±ÅŸalÄ±m.
            top_shap_features_raw = feature_importance_shap_df_V2['feature'].tolist() # V2'yi kendi SHAP df adÄ±nÄ±zla deÄŸiÅŸtirin
            pdp_features_to_plot = []
            for f_name_shap in top_shap_features_raw:
                original_f_name = f_name_shap.split('__')[-1] # 'num__sicaklik' -> 'sicaklik'
                if original_f_name in final_numerical_features and original_f_name not in ['yil','ay','gun','haftanin_gunu','yilin_gunu','hafta_numarasi']: # Zaman Ã¶zelliklerini hariÃ§ tutalÄ±m
                     if original_f_name not in pdp_features_to_plot:
                        pdp_features_to_plot.append(original_f_name)
                if len(pdp_features_to_plot) >= 3: break # Ä°lk 3 sayÄ±sal Ã¶zelliÄŸi al

            if pdp_features_to_plot:
                 print(f"\nPDP iÃ§in seÃ§ilen Ã¶zellikler: {pdp_features_to_plot}")
                 PartialDependenceDisplay.from_estimator(
                     shap_pipeline_to_analyze, X_train, pdp_features_to_plot, # X_train burada ham, Ã¶n iÅŸlenmemiÅŸ olmalÄ±
                     kind="average", n_jobs=-1, grid_resolution=30
                 )
                 plt.suptitle(f'{shap_model_to_analyze_name} iÃ§in PDP (Hata Var OlasÄ±lÄ±ÄŸÄ±)', y=1.02, fontsize=16)
                 plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show()
            else:
                print("PDP iÃ§in Ã§izdirilecek uygun sayÄ±sal Ã¶zellik bulunamadÄ±.")
        else:
            print("PDP iÃ§in Ã¶zellik Ã¶nemi verisi (SHAP) bulunamadÄ±.")


    except Exception as e_detail:
        print(f"DetaylÄ± analiz (SHAP/PDP) sÄ±rasÄ±nda hata: {type(e_detail).__name__}: {e_detail}")
else:
    print("\nDetaylÄ± analiz (SHAP/PDP) iÃ§in en iyi model belirlenemedi veya uygun deÄŸil.")


# Ã–RNEK TAHMÄ°N (Mevcut kodunuzdaki gibi)
if best_model_overall_pipeline:
    print(f"\nğŸ“¦ {best_model_overall_name} Modeli ile Ã–rnek Tahmin:")
    # ... (Mevcut Ã¶rnek tahmin kodunuz buraya, X_test'in ham halini kullanarak) ...

print("\n--- ANALÄ°Z VE MODELLEME TAMAMLANDI ---")
